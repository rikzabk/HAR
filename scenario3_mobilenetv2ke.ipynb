{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 3: MobileNetV2 with Keyframe Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "# General Libraries\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import itertools\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Katna Libraries\n",
    "from Katna.video import Video\n",
    "from Katna.writer import KeyFrameDiskWriter\n",
    "\n",
    "# Data Preprocessing Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Adam Optimizer Libraries\n",
    "from keras.optimizers.legacy import Adam # for Apple Silicon\n",
    "# from keras.optimizers import Adam # for Windows\n",
    "\n",
    "# MobileNetV2 Libraries\n",
    "from keras.utils import plot_model\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Evaluation Libraries\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Information Function\n",
    "def data_information(dataframe, file_output_path, filename):\n",
    "    file_type = dataframe.columns[1].split()[0]\n",
    "\n",
    "    # Check if folder exists\n",
    "    if not os.path.exists(file_output_path):\n",
    "        os.makedirs(file_output_path)\n",
    "\n",
    "    # Writing the data information to a text file\n",
    "    with open(os.path.join(file_output_path, f\"data_information_{filename}.txt\"), 'w') as f:\n",
    "        f.write(\"*\"*50)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"*\"*50)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"DATA INFORMATION\".center(50))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"*\"*50)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(f\"Number of Labels : {dataframe['Label Type'].nunique()} Labels\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(f\"Number of {file_type}s : {len(dataframe)} {file_type}s\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"*\"*50)\n",
    "        f.write(\"\\n\")\n",
    "        for i in dataframe['Label Type'].value_counts().index:\n",
    "            f.write(f\"{i.ljust(20)} : {dataframe['Label Type'].value_counts()[i]} videos\")\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"*\"*50)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"*\"*50)\n",
    "    \n",
    "    # save dataframe to csv\n",
    "    dataframe.to_csv(os.path.join(file_output_path, f\"dataframe_{filename}.csv\"), index=False)\n",
    "    \n",
    "    # showing the data information\n",
    "    with open(os.path.join(file_output_path, f\"data_information_{filename}.txt\"), 'r') as f:\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Initialization Function\n",
    "def data_initialization(dataset_path, file_output_path):\n",
    "    # get the list of all the label types\n",
    "    label_type = [item for item in os.listdir(dataset_path) if not item.startswith('.')]\n",
    "    \n",
    "    # get the list of all the videos\n",
    "    activities = []\n",
    "    for label in label_type:\n",
    "        all_items = os.listdir(os.path.join(dataset_path, label))\n",
    "        for item in all_items:\n",
    "            if item.startswith('.'):\n",
    "                continue\n",
    "            else:\n",
    "                videos = os.listdir(os.path.join(dataset_path, label, item))\n",
    "            for video in videos:\n",
    "                if video.endswith('.mp4'):      # can be changed to any other video format\n",
    "                    activities.append((label, os.path.join(dataset_path, label, item, video)))\n",
    "    \n",
    "    # create a dataframe\n",
    "    df = pd.DataFrame(activities, columns=['Label Type', 'Video Path'])\n",
    "\n",
    "    # print data information\n",
    "    data_information(dataframe=df, file_output_path=file_output_path, filename=\"data_initialization\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyframe Extraction Function\n",
    "def keyframe_extraction(dataframe, extracted_keyframes_output_folder, no_of_frames_to_returned):\n",
    "  # start time\n",
    "  start_time = time.time()\n",
    "\n",
    "  # print initial message\n",
    "  print(f\"Extracting Keyframes from {len(dataframe)} videos...\")\n",
    "  \n",
    "  # create a directory to save the keyframes\n",
    "  os.makedirs(extracted_keyframes_output_folder, exist_ok=True)\n",
    "\n",
    "  # For windows, the below if condition is must.\n",
    "  if __name__ == \"__main__\":\n",
    "    # initialize video module\n",
    "    vd = Video()\n",
    "\n",
    "    # number of images to be returned\n",
    "    no_of_frames_to_returned = no_of_frames_to_returned # can be changed as per requirement\n",
    "\n",
    "  # Extracting keyframe from all videos\n",
    "  for i in tqdm(range(len(dataframe)), desc=\"Extracting Keyframes from Videos\", colour='green'):\n",
    "    # initialize diskwriter to save data at desired location\n",
    "    diskwriter = KeyFrameDiskWriter(location=extracted_keyframes_output_folder + \"/\" + dataframe.iloc[i]['Label Type'])\n",
    "\n",
    "    # Video file path\n",
    "    video_file_path = dataframe.iloc[i]['Video Path']\n",
    "\n",
    "    # extract keyframes and process data with diskwriter\n",
    "    vd.extract_video_keyframes(\n",
    "      no_of_frames=no_of_frames_to_returned, \n",
    "      file_path=video_file_path,\n",
    "      writer=diskwriter\n",
    "    )\n",
    "\n",
    "  # end time\n",
    "  end_time = time.time()\n",
    " \n",
    "  # round the execution time to 2 decimal places\n",
    "  exec_time = end_time - start_time\n",
    "  exec_time = round(exec_time, 2)\n",
    "\n",
    "  # print final message\n",
    "  print(\"Keyframes extracted successfully!\")\n",
    "  print(f\"Keyframes extracted from {len(dataframe)} videos and saved in {extracted_keyframes_output_folder}\")\n",
    "  print(f\"Time taken to extract keyframes from {len(dataframe)} videos : {exec_time} seconds\")\n",
    "\n",
    "  return exec_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Initialization for Split Function\n",
    "def data_initialization_split(dataset_path, file_output_path):\n",
    "    # get the list of all the label types\n",
    "    label_type = [item for item in os.listdir(dataset_path) if not item.startswith('.')]\n",
    "    \n",
    "    # get the list of all the videos\n",
    "    activities = []\n",
    "    for label in label_type:\n",
    "        if label.startswith('.'):\n",
    "            continue\n",
    "        videos = os.listdir(os.path.join(dataset_path, label))\n",
    "        for video in videos:\n",
    "            if video.endswith('.jpeg'):     # can add or change the image format\n",
    "                activities.append((label, os.path.join(dataset_path, label, video)))\n",
    "    \n",
    "    # create a dataframe\n",
    "    df_extract = pd.DataFrame(activities, columns=['Label Type', 'Image Path'])\n",
    "\n",
    "    data_information(dataframe=df_extract, file_output_path=file_output_path, filename=\"data_initialization_split\")\n",
    "    \n",
    "    return df_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Files Function\n",
    "def copy_files(train_dataframe, test_dataframe):\n",
    "    # load variables\n",
    "    dataframes = [train_dataframe, test_dataframe]\n",
    "    destination_folder = 'SplittedFrames/extractedKeyframes' # change the destination folder according to the need\n",
    "\n",
    "    for dataframe in dataframes:\n",
    "        # set the destination folder\n",
    "        if dataframe is train_dataframe:\n",
    "            destination = os.path.join(destination_folder, 'train')\n",
    "            current_dataframe = \"Train\"\n",
    "        else:\n",
    "            destination = os.path.join(destination_folder, 'test')\n",
    "            current_dataframe = \"Test\"\n",
    "        \n",
    "        # Iterate over each row in the dataframe and copy the file to the destination folder\n",
    "        for index, row in tqdm(\n",
    "            dataframe.iterrows(), \n",
    "            total=len(dataframe), \n",
    "            desc=f\"Copying splitted {current_dataframe} files          \", \n",
    "            unit=\"files\", \n",
    "            position=0, \n",
    "            leave=True, \n",
    "            colour=\"green\"):\n",
    "            # Get the source and destination paths\n",
    "            source_path = row['Image Path']\n",
    "            destination_subfolder = row['Label Type']\n",
    "            destination_path = os.path.join(destination, destination_subfolder, os.path.basename(source_path))\n",
    "\n",
    "            # Create the destination subfolder if it doesn't exist\n",
    "            os.makedirs(os.path.join(destination, destination_subfolder), exist_ok=True)\n",
    "\n",
    "            # Copy the file to the destination folder\n",
    "            shutil.copyfile(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Files Function with Grayscaling\n",
    "def copy_files_grayscaled(train_dataframe, test_dataframe):\n",
    "    # load variables\n",
    "    dataframes = [train_dataframe, test_dataframe]\n",
    "    destination_folder = 'SplittedFrames/extractedKeyframes_grayscaled' # change the destination folder according to the need\n",
    "\n",
    "    for dataframe in dataframes:\n",
    "        # set the destination folder\n",
    "        if dataframe is train_dataframe:\n",
    "            destination = os.path.join(destination_folder, 'train')\n",
    "            current_dataframe = \"Train\"\n",
    "        else:\n",
    "            destination = os.path.join(destination_folder, 'test')\n",
    "            current_dataframe = \"Test\"\n",
    "        \n",
    "        # Iterate over each row in the dataframe and copy the file to the destination folder\n",
    "        for index, row in tqdm(\n",
    "            dataframe.iterrows(), \n",
    "            total=len(dataframe), \n",
    "            desc=f\"Copying splitted grayscale {current_dataframe} files \", \n",
    "            unit=\"files\", \n",
    "            position=0, \n",
    "            leave=True, \n",
    "            colour=\"green\"):\n",
    "            # Get the source and destination paths\n",
    "            source_path = row['Image Path']\n",
    "            destination_subfolder = row['Label Type']\n",
    "            destination_path = os.path.join(destination, destination_subfolder, os.path.basename(source_path))\n",
    "\n",
    "            # Create the destination subfolder if it doesn't exist\n",
    "            os.makedirs(os.path.join(destination, destination_subfolder), exist_ok=True)\n",
    "\n",
    "            # Read the image\n",
    "            image = cv2.imread(source_path)\n",
    "\n",
    "            # Convert the image to grayscale\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Save the grayscale image to the destination folder\n",
    "            cv2.imwrite(destination_path, gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data Function\n",
    "def split_data(dataframe, test_size, file_output_path):\n",
    "    # print initial message\n",
    "    print(\"Splitting the data into train and test...\")\n",
    "\n",
    "    # Split the data into train and test\n",
    "    df_train, df_test = train_test_split(dataframe, test_size=test_size, random_state=42)\n",
    "\n",
    "    # save the dataframes to csv\n",
    "    df_train.to_csv(os.path.join(file_output_path, \"dataframe_dataset_train.csv\"), index=False)\n",
    "    df_test.to_csv(os.path.join(file_output_path, \"dataframe_dataset_test.csv\"), index=False)\n",
    "\n",
    "    # # copy files to the destination folder\n",
    "    # copy_files(train_dataframe=df_train, test_dataframe=df_test)\n",
    "    # copy_files_grayscaled(train_dataframe=df_train, test_dataframe=df_test)\n",
    "\n",
    "    # print final message\n",
    "    print(\"Data split successfully into train and test!\")\n",
    "\n",
    "    # print data information\n",
    "    print(\"\\n\")\n",
    "    print(f\"Total image in train set    : {len(df_train)} images\")\n",
    "    print(f\"Total image in test set     : {len(df_test)} images\")\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation Function\n",
    "def data_augmentation(img_width, img_height, batch_size):\n",
    "    # Splitted data directories\n",
    "    train_dir = 'SplittedFrames/extractedKeyframes_grayscaled/train'\n",
    "    test_dir = 'SplittedFrames/extractedKeyframes_grayscaled/test'\n",
    "\n",
    "    # Data augmentation for training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0/255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        validation_split=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    # Data normalization for testing\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        # rescale=1.0/255,\n",
    "        # shear_range=0.2,\n",
    "        # zoom_range=0.2,\n",
    "        # horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    # Load training data\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training', \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Load validation data\n",
    "    val_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation', \n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Load testing data\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical', \n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2 Model\n",
    "def mobileNetV2_model(learning_rate, train_generator, file_output_path):\n",
    "    # Variable\n",
    "    num_classes = train_generator.num_classes\n",
    "\n",
    "    # Create the MobileNetV2 model\n",
    "    model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze the layers in the base model\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add classification layer to the model\n",
    "    model = tensorflow.keras.Sequential([\n",
    "        model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(num_classes, activation='softmax', name='predictions')\n",
    "    ])\n",
    "\n",
    "    model = Model(inputs=model.input, outputs=model.output, name='MobileNetV2')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # callbacks\n",
    "    folder_name = file_output_path\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    model_checkpoint_filename = 'Scenario3_mobilenetv2_checkpoint_epoch_{epoch:02d}_val_loss_{val_loss:.2f}_val_accuracy_{val_accuracy:.2f}_loss_{loss:.2f}_accuracy_{accuracy:.2f}.h5'\n",
    "    model_checkpoint = ModelCheckpoint(os.path.join(folder_name, model_checkpoint_filename), monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "    early_stopping = EarlyStopping(patience=5, monitor='val_accuracy', restore_best_weights=True)\n",
    "    \n",
    "    return model, model_checkpoint, early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Conversion Function\n",
    "def convert(seconds):\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    " \n",
    "    return \"%d:%02d:%02d\" % (hour, minutes, seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search Print\n",
    "def gs_print(accuracy, learning_rate, model, execution_time, file_output_path):\n",
    "    # save cell output to a text file\n",
    "    with open(os.path.join(file_output_path, \"grid_search_output.txt\"), \"w\") as f:\n",
    "        print(\"*\"*65, file=f)\n",
    "        print(\"*\"*65, file=f)\n",
    "        print(\"GRID SEARCH RESULTS\".center(65), file=f)\n",
    "        print(\"*\"*65, file=f)\n",
    "        print(f\"Best Learning Rate              : {learning_rate}\", file=f)\n",
    "        print(f\"Best Accuracy                   : {accuracy}\", file=f)\n",
    "        execution_time = convert(execution_time)\n",
    "        print(f\"Best Execution Time (seconds)   : {execution_time}\", file=f)\n",
    "        print(f\"Best Execution Time (hh:mm:ss)  : {execution_time}\", file=f)\n",
    "        print(\"*\"*65, file=f)\n",
    "        print(\"Summary of the Best Model\".center(65), file=f)\n",
    "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "        print(\"*\"*65, file=f)\n",
    "    \n",
    "    with open(os.path.join(file_output_path, \"grid_search_output.txt\"), \"r\") as f:\n",
    "        print(f.read())\n",
    "\n",
    "    # Save model plot\n",
    "    plot_model(model, to_file=os.path.join(file_output_path, \"model_plot.png\"), show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search Function\n",
    "def grid_search(learning_rate, epochs, train_generator, val_generator, file_output_path):\n",
    "    \n",
    "    # all variables\n",
    "    best_accuracy = 0\n",
    "    best_val_accuracy = 0\n",
    "    best_learning_rate = 0\n",
    "    best_execution_time = 0\n",
    "    best_model = None\n",
    "\n",
    "    # Grid Search\n",
    "    for lr in learning_rate:\n",
    "        print(f\"Learning Rate: {lr}\")\n",
    "        model, model_checkpoint, early_stopping = mobileNetV2_model(learning_rate=lr, train_generator=train_generator, file_output_path=file_output_path)\n",
    "\n",
    "        start_time = time.time()\n",
    "        history = model.fit(train_generator, validation_data=val_generator, steps_per_epoch=len(train_generator), validation_steps=len(val_generator), epochs=epochs, callbacks=[model_checkpoint, early_stopping], verbose=1)\n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        exec_time = round(exec_time, 2)\n",
    "        print(f\"Time taken to train the {lr} model : {exec_time} seconds\")\n",
    "\n",
    "        # Save history to a file\n",
    "        history_df = pd.DataFrame(history.history)\n",
    "        history_df.to_csv(os.path.join(file_output_path, 'history.csv'), index=False)\n",
    "\n",
    "        accuracy = history.history['accuracy'][-1]\n",
    "        val_accuracy = history.history['val_accuracy'][-1]\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_learning_rate = lr\n",
    "            best_model = model\n",
    "            best_execution_time = exec_time\n",
    "\n",
    "    # Save the best_model\n",
    "    best_model.save(os.path.join(file_output_path, 'best_model.h5'))\n",
    "\n",
    "    return best_accuracy, best_learning_rate, best_model, best_execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model Plot Function\n",
    "def save_plot_model(file_output_path):\n",
    "    # history\n",
    "    history = pd.read_csv(os.path.join(file_output_path, 'history.csv'))\n",
    "\n",
    "    # plot the accuracy and loss of the model side by side\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # plot the accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # plot the loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # save the plot\n",
    "    plt.savefig(os.path.join(file_output_path, 'model_accuracy_loss.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Function\n",
    "def evaluate_model(test_generator, file_output_path):\n",
    "    # load the best model\n",
    "    model = load_model(os.path.join(file_output_path, 'best_model.h5'))\n",
    "\n",
    "    # evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=1)\n",
    "\n",
    "    # save the evaluation results csv\n",
    "    evaluation_results = pd.DataFrame({'Test Loss': [test_loss], 'Test Accuracy': [test_accuracy]})\n",
    "    evaluation_results.to_csv(os.path.join(file_output_path, 'model_evaluation_results.csv'), index=False)\n",
    "\n",
    "    # show the evaluation results csv\n",
    "    print(\"\\n\")\n",
    "    print(\"*\"*75)\n",
    "    print(tabulate(evaluation_results, headers='keys', tablefmt='pretty'))\n",
    "    print(f\"Model evaluation results saved in {file_output_path} as model_evaluation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Model Function\n",
    "def predict_model(test_generator, file_output_path):\n",
    "    \"\"\"\n",
    "    Predicts the classes for the given test data using a trained model and saves the predictions, evaluation results,\n",
    "    confusion matrix, and classification report to CSV files.\n",
    "\n",
    "    Args:\n",
    "        test_generator (object): The test data generator.\n",
    "        file_output_path (str): The path to save the output files.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # model predictions\n",
    "    # load the model\n",
    "    model = load_model(os.path.join(file_output_path, 'best_model.h5'))\n",
    "    test_dir = 'SplittedFrames/extractedKeyframes_grayscaled/test'\n",
    "\n",
    "    actual_classes = []\n",
    "    predicted_classes = []\n",
    "    predicted_probabilities = []\n",
    "\n",
    "\n",
    "\n",
    "    # Get the total number of files\n",
    "    total_files = sum(len(files) for _, _, files in os.walk('SplittedFrames/extractedKeyframes_grayscaled/test'))\n",
    "\n",
    "    # Create a progress bar\n",
    "    progress_bar = tqdm(total=total_files, desc='Loading')\n",
    "\n",
    "    for folder in os.listdir(test_dir):\n",
    "        if folder.startswith('.'):\n",
    "            continue\n",
    "        for file in os.listdir(os.path.join(test_dir, folder)):\n",
    "            if file.startswith('.'):\n",
    "                continue\n",
    "            actual_classes.append(test_generator.class_indices[folder])\n",
    "\n",
    "            img = cv2.imread(os.path.join(test_dir, folder, file))\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            img_normalized = img / 255.0\n",
    "            img_array = np.array([img_normalized])\n",
    "\n",
    "            pred = model.predict(img_array, verbose=0)\n",
    "            predicted_probabilities.append(np.array(pred))\n",
    "            predictions = np.argmax(pred)\n",
    "            predicted_classes.append(predictions)\n",
    "            \n",
    "            # Update the progress bar\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "    # Close the progress bar\n",
    "    progress_bar.close()\n",
    "\n",
    "    # get the class labels\n",
    "    class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "\n",
    "    \n",
    "    # model predictions evaluation\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(actual_classes, predicted_classes)\n",
    "\n",
    "    # classification report\n",
    "    cr = classification_report(actual_classes, predicted_classes, target_names=class_labels)\n",
    "    \n",
    "    # accuracy\n",
    "    accuracy = accuracy_score(actual_classes, predicted_classes)\n",
    "\n",
    "    # precision\n",
    "    precision = precision_score(actual_classes, predicted_classes, average='weighted')\n",
    "\n",
    "    # recall\n",
    "    recall = recall_score(actual_classes, predicted_classes, average='weighted')\n",
    "\n",
    "    # f1-score\n",
    "    f1 = f1_score(actual_classes, predicted_classes, average='weighted')\n",
    "\n",
    "\n",
    "    \n",
    "    # print the confusion matrix and classification report\n",
    "    print(\"\\n\")\n",
    "    print(\"*\"*75)\n",
    "    print(\"Confusion Matrix\".center(75))\n",
    "    print(cm)\n",
    "    print(\"*\"*75)\n",
    "    print(\"Classification Report\".center(75))\n",
    "    print(cr)\n",
    "    print(\"*\"*75)\n",
    "    \n",
    "    # plot confusion matrix\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_labels))\n",
    "    plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "    plt.yticks(tick_marks, class_labels)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(file_output_path, 'confusion_matrix.png'))\n",
    "\n",
    "    \n",
    "    # save the evaluation results\n",
    "    print(\"\\n\")\n",
    "    print(\"*\"*75) \n",
    "    # save the model predictions to a csv\n",
    "    predicted_probabilities = np.array(predicted_probabilities)\n",
    "    predicted_probabilities = np.squeeze(predicted_probabilities, axis=1)\n",
    "    predictions_df = pd.DataFrame(predicted_probabilities, columns=class_labels)\n",
    "    predictions_df['Actual Class'] = actual_classes\n",
    "    predictions_df['Predicted Class'] = predicted_classes\n",
    "    predictions_df.to_csv(os.path.join(file_output_path, 'model_predictions.csv'), index=False)\n",
    "    print(f\"Model predictions saved in {file_output_path} as model_predictions.csv\")\n",
    "\n",
    "    # save the predictions evaluation results to a csv\n",
    "    predictions_evaluation_results = pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1-Score': [f1]})\n",
    "    predictions_evaluation_results.to_csv(os.path.join(file_output_path, 'model_predictions_evaluation_results.csv'), index=False)\n",
    "    print(f\"Model predictions evaluation results saved in {file_output_path} as model_predictions_evaluation_results.csv\")\n",
    "    \n",
    "    # save the confusion matrix to a csv\n",
    "    cm_df = pd.DataFrame(cm, columns=class_labels, index=class_labels)\n",
    "    cm_df.to_csv(os.path.join(file_output_path, 'confusion_matrix.csv'))\n",
    "    print(\"Confusion matrix saved in {file_output_path} as confusion_matrix.csv\")\n",
    "\n",
    "    # save the classification report to a csv\n",
    "    cr = classification_report(actual_classes, predicted_classes, target_names=class_labels, output_dict=True)\n",
    "    cr_df = pd.DataFrame(cr).transpose()\n",
    "    cr_df.to_csv(os.path.join(file_output_path, 'classification_report.csv'))\n",
    "    print(\"Classification report saved in {file_output_path} as classification_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** PRIORITIZING MEMORY GPU FOR PROCESSING *****************\n",
      "GPU is available\n",
      "Physical devices cannot be modified after being initialized\n",
      "***************************************************************************\n",
      "Num GPUs Available:  1\n",
      "***************************************************************************\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n",
      "***************************************************************************\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "***************************************************************************\n",
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "# Prioritizing memory GPU for processing (IMPORTANT)\n",
    "print(\" Prioritizing memory GPU for processing \".upper().center(75, \"*\"))\n",
    "\n",
    "gpus = tensorflow.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  print(\"GPU is available\")\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tensorflow.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tensorflow.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "print(\"*\"*75)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))\n",
    "\n",
    "# tensorflow.debugging.set_log_device_placement(True)  # log device placement\n",
    "\n",
    "print(\"*\"*75)\n",
    "\n",
    "# Place tensors on the CPU\n",
    "with tensorflow.device('/GPU:0'):\n",
    "  a = tensorflow.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tensorflow.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "# Run on the GPU\n",
    "c = tensorflow.matmul(a, b)\n",
    "print(c)\n",
    "\n",
    "print(\"*\"*75)\n",
    "\n",
    "# change processing to GPU\n",
    "print(tensorflow.config.list_physical_devices('GPU'))\n",
    "\n",
    "print(\"*\"*75)\n",
    "\n",
    "# select GPU\n",
    "gpus = tensorflow.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tensorflow.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tensorflow.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Variables\n",
    "dataset_path = 'Dataset/UCF11_updated_mpg/'\n",
    "extracted_keyframes = 'Frames/extractedKeyframes/'\n",
    "file_output_path = 'Model/Scenario3/'  # try to change pooling from GAP to GMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "**************************************************\n",
      "                 DATA INFORMATION                 \n",
      "**************************************************\n",
      "Number of Labels : 11 Labels\n",
      "Number of Videos : 1600 Videos\n",
      "**************************************************\n",
      "horse_riding         : 198 videos\n",
      "tennis_swing         : 167 videos\n",
      "soccer_juggling      : 156 videos\n",
      "diving               : 156 videos\n",
      "biking               : 145 videos\n",
      "golf_swing           : 142 videos\n",
      "basketball           : 141 videos\n",
      "swing                : 137 videos\n",
      "walking              : 123 videos\n",
      "trampoline_jumping   : 119 videos\n",
      "volleyball_spiking   : 116 videos\n",
      "**************************************************\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Data initialization\n",
    "df_dataset = data_initialization(dataset_path=dataset_path, file_output_path=file_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Label Type                                         Video Path\n",
      "0     volleyball_spiking  Dataset/UCF11_updated_mpg/volleyball_spiking/v...\n",
      "1     volleyball_spiking  Dataset/UCF11_updated_mpg/volleyball_spiking/v...\n",
      "2     volleyball_spiking  Dataset/UCF11_updated_mpg/volleyball_spiking/v...\n",
      "3     volleyball_spiking  Dataset/UCF11_updated_mpg/volleyball_spiking/v...\n",
      "4     volleyball_spiking  Dataset/UCF11_updated_mpg/volleyball_spiking/v...\n",
      "...                  ...                                                ...\n",
      "1595              diving  Dataset/UCF11_updated_mpg/diving/v_diving_08/v...\n",
      "1596              diving  Dataset/UCF11_updated_mpg/diving/v_diving_08/v...\n",
      "1597              diving  Dataset/UCF11_updated_mpg/diving/v_diving_08/v...\n",
      "1598              diving  Dataset/UCF11_updated_mpg/diving/v_diving_08/v...\n",
      "1599              diving  Dataset/UCF11_updated_mpg/diving/v_diving_08/v...\n",
      "\n",
      "[1600 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Show the dataset dataframe\n",
    "df_dataset = pd.read_csv(os.path.join(file_output_path, 'dataframe_data_initialization.csv'))\n",
    "print(df_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Skip Keyframe Extraction if already done\n",
    "# # Keyframe extraction\n",
    "# number_of_keyframes = 100\n",
    "# keyframe_extraction_execution_time = keyframe_extraction(dataframe=df_dataset, \n",
    "#                                                          extracted_keyframes_output_folder=extracted_keyframes,\n",
    "#                                                          no_of_frames_to_returned=number_of_keyframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Skip Keyframe Extraction if already done\n",
    "# # Print the keyframe extraction execution time\n",
    "# with open(os.path.join(file_output_path, 'keyframe_extraction_execution_time.txt'), 'w') as f:\n",
    "#     f.write(str(keyframe_extraction_execution_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "**************************************************\n",
      "                 DATA INFORMATION                 \n",
      "**************************************************\n",
      "Number of Labels : 11 Labels\n",
      "Number of Images : 14548 Images\n",
      "**************************************************\n",
      "soccer_juggling      : 2400 videos\n",
      "horse_riding         : 1833 videos\n",
      "biking               : 1534 videos\n",
      "walking              : 1384 videos\n",
      "tennis_swing         : 1268 videos\n",
      "diving               : 1262 videos\n",
      "golf_swing           : 1194 videos\n",
      "trampoline_jumping   : 1102 videos\n",
      "swing                : 1069 videos\n",
      "basketball           : 951 videos\n",
      "volleyball_spiking   : 551 videos\n",
      "**************************************************\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Data initialization for splitting the dataset\n",
    "df_dataset_extracted  = data_initialization_split(dataset_path=extracted_keyframes, file_output_path=file_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Label Type                                         Image Path\n",
      "0      volleyball_spiking  Frames/extractedKeyframes/volleyball_spiking/v...\n",
      "1      volleyball_spiking  Frames/extractedKeyframes/volleyball_spiking/v...\n",
      "2      volleyball_spiking  Frames/extractedKeyframes/volleyball_spiking/v...\n",
      "3      volleyball_spiking  Frames/extractedKeyframes/volleyball_spiking/v...\n",
      "4      volleyball_spiking  Frames/extractedKeyframes/volleyball_spiking/v...\n",
      "...                   ...                                                ...\n",
      "14543              diving  Frames/extractedKeyframes/diving/v_diving_16_0...\n",
      "14544              diving  Frames/extractedKeyframes/diving/v_diving_03_0...\n",
      "14545              diving  Frames/extractedKeyframes/diving/v_diving_06_0...\n",
      "14546              diving  Frames/extractedKeyframes/diving/v_diving_15_0...\n",
      "14547              diving  Frames/extractedKeyframes/diving/v_diving_01_0...\n",
      "\n",
      "[14548 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# show dataframe from csv\n",
    "df_datasplit = pd.read_csv(os.path.join(file_output_path, 'dataframe_data_initialization_split.csv'))\n",
    "print(df_datasplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Skip splitting data if already done\n",
    "# # Split data\n",
    "\n",
    "# # variable\n",
    "# test_size = 0.2\n",
    "\n",
    "# # Split data into train and test\n",
    "# df_train, df_test = split_data(dataframe=df_datasplit, test_size=test_size, file_output_path=file_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9316 images belonging to 11 classes.\n",
      "Found 2322 images belonging to 11 classes.\n",
      "Found 2910 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "\n",
    "# Image size\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Load data\n",
    "train_generator, val_generator, test_generator = data_augmentation(img_width, img_height, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the grid search function\n",
    "learning_rate = [0.0001]\n",
    "epochs = 100\n",
    "\n",
    "best_accuracy, best_learning_rate, best_model, best_execution_time = grid_search(learning_rate, epochs, train_generator, val_generator, file_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print grid search results\n",
    "gs_print(accuracy=best_accuracy, learning_rate=best_learning_rate, model=best_model, execution_time=best_execution_time, file_output_path=file_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model Plot\n",
    "save_plot_model(file_output_path=file_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "evaluate_model(test_generator=test_generator, file_output_path=file_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Model\n",
    "predict_model(test_generator=test_generator, file_output_path=file_output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
